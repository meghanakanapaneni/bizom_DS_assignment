{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive"
      ],
      "metadata": {
        "id": "AOUq2efuLRlt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cIbWSmnjLNjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576850fe-7d03-4efc-c8a8-b4aa2912735d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "ACVsqK0VLWg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import glob\n",
        "from csv import writer\n",
        "import csv\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import Image as ig\n",
        "from PIL import Image as im\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "SH3X6SEjLX-e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHlchGjciJ7y",
        "outputId": "297b7fc3-8e9e-4af6-8745-f85be071cff4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_PATH_1 = '/content/gdrive/My Drive/Mobisy/trainedModels/mnist_image_classification_model.pt'\n",
        "FILE_PATH_2 = '/content/gdrive/My Drive/Mobisy/trainedModels/summation_model.pt'"
      ],
      "metadata": {
        "id": "N1x7AlVWLfjK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 - Classification Model"
      ],
      "metadata": {
        "id": "VTtK7Df8h58M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1) \n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=1)                                  \n",
        "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=2)                               \n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=1)                                  \n",
        "        self.fc1 = nn.Linear(8*11*11, 120)\n",
        "        self.fc2 = nn.Linear(120, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu(self.conv1(x)))         # output: 26*26 -> # output: 25*25\n",
        "        x = self.pool2(self.relu(self.conv2(x)))         # output:  12*12 -> 11*11\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net1 = Model1()"
      ],
      "metadata": {
        "id": "Bxx1uGO0h3BC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2 - Summation of 2 Numbers"
      ],
      "metadata": {
        "id": "B4ZZCmR6h9zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model2, self).__init__()                             \n",
        "        self.fc1 = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "net2 = Model2()"
      ],
      "metadata": {
        "id": "v7j3y8Chh3Ko"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9sva8lPwLp-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model 1"
      ],
      "metadata": {
        "id": "vXzZtGhrLtXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net1.load_state_dict(torch.load(FILE_PATH_1))\n",
        "net1.eval()"
      ],
      "metadata": {
        "id": "h_7QAzMCLtpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "309051bd-23bc-425a-ec12-f138d9638ac9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model1(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=968, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model 2\n"
      ],
      "metadata": {
        "id": "fWbrNLlbLuAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2.load_state_dict(torch.load(FILE_PATH_2))\n",
        "net2.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eAGy5G8Lume",
        "outputId": "750ddae2-abf5-42eb-c664-22b7f922e447"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model2(\n",
              "  (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Image"
      ],
      "metadata": {
        "id": "bjgQGH1hL9x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/gdrive/My Drive/Mobisy/trainingSet/'\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.Grayscale(1),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Grayscale(1),\n",
        "    ]),\n",
        "}\n",
        "image_datasets = {x: datasets.ImageFolder(root=os.path.join(data_path, x),transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "target = image_datasets['train'].classes"
      ],
      "metadata": {
        "id": "ErIyA0nsjo2i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testImage(model, PATH):\n",
        "    image = Image.open(PATH)\n",
        "    model = model.to(device)\n",
        "    transform = transforms.ToTensor()\n",
        "    img_tensor = transform(image)\n",
        "    img_tensor = torch.unsqueeze(img_tensor, 0)\n",
        "    model.to(device)\n",
        "    img_tensor = img_tensor.to(device)\n",
        "    img_tensor = img_tensor.float()\n",
        "    pred = model(img_tensor)\n",
        "    check = F.softmax(pred, dim=1)\n",
        "    idx = torch.argmax(check, dim=1)\n",
        "    \n",
        "    return target[idx]"
      ],
      "metadata": {
        "id": "A9oxW522L-XS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Summation"
      ],
      "metadata": {
        "id": "yQs26_hGMFgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def testSummation(model,input):\n",
        "    pred=model(input)\n",
        "    return pred.item()\n"
      ],
      "metadata": {
        "id": "WvjPu984MF7L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Test Images"
      ],
      "metadata": {
        "id": "5LPt7yZ9OcS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(original,predicted):\n",
        "  acc=0\n",
        "  for i in range(0,len(predicted)):\n",
        "    if(original[i]==predicted[i]):\n",
        "      acc=acc+1\n",
        "  print(\"Test set accuracy: \",acc/len(predicted))"
      ],
      "metadata": {
        "id": "6JJ57Nw_Idle"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Result"
      ],
      "metadata": {
        "id": "i-k4kUZ7OglD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index=0\n",
        "test_result=[]\n",
        "test_data=pd.read_csv('/content/gdrive/My Drive/Mobisy/test_data.csv')\n",
        "for ind in test_data.index:\n",
        "  image_output=int(testImage(net1,'/'+test_data['file_path'][ind][1:]))\n",
        "  second_model_input=[[image_output,test_data['random_number'][ind]]]\n",
        "  second_input = torch.as_tensor(second_model_input).to(device)\n",
        "  second_input=second_input.float()\n",
        "  summation=testSummation(net2,second_input)\n",
        "  #print(test_data['file_path'][ind],image_output,second_model_input,summation)\n",
        "  test_result.append(round(summation))\n",
        "evaluate(test_data['sum'],test_result)\n"
      ],
      "metadata": {
        "id": "DTi2pAQ2Og17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f050e67-b4ae-4752-92af-41a9fdf25258"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy:  0.9028571428571428\n"
          ]
        }
      ]
    }
  ]
}